\chapter{Results}

After having created a gold standard (see Chapter~\ref{chap:gold-standard}) for evaluating the quality of the alignments, I compared the alignments computed by SimAlign with the alignments computed by a baseline system.
I shall now proceed present the results of the experiment.

\section{Baseline System}
As a baseline system, I chose \texttt{fast\_align} \autocite{dyer-etal-2013-simple}. 
\texttt{fast\_align} is a re-parameterization of the IBM Model 2. 
It has become a popular seccessor to Giza++, serves as a baseline system in other works, and is even recommended by WHO? as an alternative for Giza++ for computing the word alignments for Moses SMT. 
It outperforms Giza++ in many scenarios.

\texttt{fast\_align} is extremely fast---computing the word alignments for the around \numprint{80000} sentence pairs took around 50 seconds. 
It is well documented and is extremely easy to compile and to operate. 
All of this makes \texttt{fast\_align} the most attractive system to use as a baseline system.



\begin{table}
\centering
\begin{tabular}{lllllll}
\toprule
											&Method &Dataset Size & Percision & Recall & $F_1$    & AER \\
\midrule 
\multirow{6}{1em}{\rotatebox{90}{Baseline}}& fast\_align & \numprint{79109}	  & \textbf{0.625}	  & \textbf{0.786}  & \textbf{0.696} & \textbf{0.304} \\
									    	& " &50k         & 0.622	  & 0.775  & 0.69  & 0.31  \\
									    	& " & 25k         & 0.602	  & 0.751  & 0.668 & 0.332 \\
									    	& " & 10k   	  & 0.58	  & 0.725  & 0.644 & 0.355 \\
									    	& " & 5k 		  & 0.565	  & 0.709  & 0.629 & 0.371 \\
									    	& " & 600 		  & 0.515	  & 0.644  & 0.572 & 0.427 \\
\bottomrule
\end{tabular}
\caption{Evaluation metrics for word alignments with the baseline model (fast\_align) for different dataset sizes.
\enquote{Dataset Size} refers to the number of sentence pairs. }
\end{table}


\begin{table}
\centering
\begin{tabular}{llllcccc}
\toprule
	                                       &	 Embedding	     & Level		              & Method & Percision & Recall & $F_1$     & AER \\
\midrule
\multirow{9}{1em}{\rotatebox{90}{SimAlign}} & \multirow{3}{*}{mBert} & \multirow{3}{*}{BPE}  &  Argmax & \textbf{0.894}    & 0.622	& 0.734  & 0.266 \\
											&							&				     &  Itermax & 0.832  		  & 0.731	& 0.778  & 0.222 \\
											&						  &						 &  Match   & 0.795   		 & \textbf{0.767}  & \textbf{0.781}  & \textbf{0.219} \\	
											\cmidrule{2-8}
											& \multirow{6}{*}{XLM-R} & \multirow{3}{*}{Word} &  Argmax  & \textbf{0.848}	  		 & 0.399  & 0.543  & 0.457 \\
											&						&						 & Itermax  & 0.767  		  & 0.504  & 0.608  & 0.391 \\
											&						&					     & Match    & 0.67   		  & 0.647	& \textbf{0.658}	 & \textbf{0.342} \\
																	\cmidrule{3-8}
											&						& \multirow{3}{*}{BPE}	 &	Argmax  & 0.773   		 & 0.488  & 0.598  & 0.402 \\
											&					    &						 & Itermax  & 0.671  		  & 0.595  & 0.631  & 0.369 \\
											&						&						& Match		& 0.558	 		  & \textbf{0.719}  & 0.628  & 0.372 \\


\bottomrule
\end{tabular}
\caption{Evaluation metrics for word alignments using SimAlign, with different embeddings and word/sub-word level. 
Best result per embedding type in bold.}
\label{tab:simalign}
\end{table}

